<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Evaluating Relative Localization</title>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">
  <style>
    html {
      scroll-behavior: smooth;
    }
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }
    body {
      font-family: 'Roboto', sans-serif;
      background: #f4f4f4;
      padding-top: 140px;
      color: #333;
    }
    header {
      background: #003366;
      color: white;
      padding: 20px 0;
      position: fixed;
      width: 100%;
      top: 0;
      z-index: 1000;
      box-shadow: 0 2px 5px rgba(0,0,0,0.2);
    }
    nav {
      display: flex;
      justify-content: center;
      gap: 30px;
    }
    nav a {
      color: white;
      text-decoration: none;
      font-weight: bold;
      font-size: 16px;
    }
    nav a:hover {
      text-decoration: underline;
    }
    .drone-animation {
      margin-top: 20px;
      display: flex;
      justify-content: center;
      align-items: center;
      gap: 80px;
    }
    .drone {
      width: 60px;
      animation: hover 2s ease-in-out infinite;
    }
    .drone-left {
      animation-delay: 0s;
    }
    .drone-right {
      animation-delay: 1s;
    }
    .fau-logo {
      width: 100px;
      height: auto;
    }
    @keyframes hover {
      0%, 100% {
        transform: translateY(0);
      }
      50% {
        transform: translateY(-15px);
      }
    }
    .hero-title {
      text-align: center;
      font-size: 32px;
      color: #003366;
      font-weight: bold;
      margin-top: 30px;
    }
    .container {
      max-width: 900px;
      margin: 60px auto;
      padding: 20px;
      background: white;
      box-shadow: 0 0 10px rgba(0,0,0,0.1);
    }
    h2 {
      color: #003366;
      margin-bottom: 20px;
      text-align: center;
      font-size: 28px;
    }
    p, a {
      font-size: 16px;
      line-height: 1.6;
    }
    img, video {
      display: block;
      margin: 20px auto;
      max-width: 90%;
      height: auto;
      border: none;
    }
    #authors {
      text-align: center;
      margin-top: 60px;
    }
    .author-row {
      display: flex;
      justify-content: center;
      flex-wrap: wrap;
      gap: 40px;
      margin-top: 20px;
    }
    .author img {
      width: 120px;
      height: 120px;
      border-radius: 50%;
      object-fit: cover;
      box-shadow: 0 0 6px rgba(0,0,0,0.1);
      margin-bottom: 10px;
    }
    .author p {
      font-weight: bold;
      font-size: 16px;
      color: #4285F4;
    }
    .lab-name {
      margin-top: 20px;
      font-size: 18px;
      color: #333;
    }
    footer {
      text-align: center;
      margin-top: 60px;
      padding: 20px;
      background: #003366;
      color: white;
    }
  </style>
</head>
<body>
  <header>
    <nav>
      <a href="#authors">Authors</a>
      <a href="#abstract">Abstract</a>
      <a href="#figures">Figures</a>
      <a href="#video">Video</a>
      <a href="pdfs/FCRAR_FINAL_DRAFT.pdf" target="_blank">Download PDF</a>
    </nav>
  </header>

  <div class="drone-animation">
    <img src="images/drone_icon.png" class="drone drone-left" alt="Drone Left">
    <img src="images/fau_owl.png" class="fau-logo" alt="FAU Owl Logo">
    <img src="images/drone_icon.png" class="drone drone-right" alt="Drone Right">
  </div>

  <h1 class="hero-title">Evaluating Relative Localization in GPS-Denied Environments Using Starling2 UAVs</h1>

  <div class="container">
    <section>
      <p>Accurate relative localization is critical for enabling autonomous behaviors in multi-agent UAV systems, such as formation flight, cooperative mapping, and search-and-rescue coordination. While GPS offers reliable global positioning outdoors, it becomes unreliable or unavailable in certain outdoor environments such as mountains, oceans, or even deep space. In such GPS-denied scenarios, relative localization must rely on onboard sensors such as cameras, IMUs, and visual markers.</p>
      <img src="images/drone_schematic.jpg" alt="Drone Schematic">
      <p>The Starling2 platform, developed by ModalAI, is specifically designed for autonomous operations in these types of constrained environments. It features a VOXL2 computer with an integrated IMU, stereo camera, and support for vision-based algorithms. In this study, we assess the performance of a visual relative localization method based on AprilTags and onboard sensors. To validate and benchmark performance, we compare against ground-truth pose data from an OptiTrack motion capture system.</p>
      <img src="images/experimental_setup.jpg" alt="Experimental Setup">
      <p>We designed a series of experiments using two Starling2 UAVs in a 15 ft Ã— 15 ft indoor flight arena instrumented with 12 OptiTrack cameras. Each drone was outfitted with retroreflective markers for external pose tracking. The relative localization algorithm used onboard cameras and AprilTags affixed to one of the drones (Drone B), while the other drone (Drone A) performed pose estimation.</p>
      <img src="images/plot_3d_apriltag.png" alt="3D Plot AprilTag">
      <p>To evaluate spatial performance, we recorded pose data at three discrete distances: 3 ft, 6 ft, and 12 ft. At each distance, Drone A estimated the pose data of Drone B based on onboard visual detection of the AprilTag. The true relative transform T<sub>BA</sub> was recorded simultaneously using OptiTrack.</p>
      <img src="images/drone_pov.png" alt="Drone POV">
      <p>The AprilTag-based relative localization method consistently produced usable pose estimates across all tested distances. At 3 ft, the algorithm exhibited minimal drift, with a positional error of just 3.4 cm and orientation error of 2 degrees. At 6 ft, performance remained within acceptable margins, with modest increases in error. At 12 ft, a more noticeable degradation occurred due to reduced pixel resolution and motion blur.</p>
      <img src="images/position_vs_time.png" alt="Position vs Time">
      <p>A YOLOv8s model was fine-tuned on a dataset of aerial drone imagery. Initial inference using the Starling2 front camera showed robust detection at 3 ft and 6 ft, with decreasing confidence beyond 10 ft. Bounding box centers were used to estimate relative bearing. Future work will focus on incorporating depth cues to estimate full pose data.</p>
      <img src="images/terminal_output.png" alt="Terminal Output">
    </section>
  </div>
</body>
</html>
